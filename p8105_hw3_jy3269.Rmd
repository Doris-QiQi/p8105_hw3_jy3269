---
title: "p8105_hw3_jy3269"
author: "Jingyi Yao"
date: "`r Sys.Date()`"
output: github_document
---

```{r,warning=FALSE, message=FALSE}
library(tidyverse)
library(p8105.datasets)
```

## Problem 2

### 1. import csv file
```{r}
data_1 <- read_csv("./data/accel_data.csv")
data_1

```

### 2. clean, tidy and wrangle data

```{r}
acc_1 <- data_1 %>% 
  janitor::clean_names() %>% 
  mutate(
    week = as.integer(week),
    day_id = as.integer(day_id),
    day = factor(day,levels= c("Monday", 
    "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday","Sunday")),
    weekday_vs_weekend = if_else(day == "Saturday" | day == "Sunday","weekend","weekday") # new variable indicate whether the day is weekend or weekday
  ) %>% 
  pivot_longer(                          # switch the data set from wider to longer
    activity_1:activity_1440,
    names_to = "minute",                 # activity_number in previous column names indicate the minute       
    names_prefix = "activity_",          # remove the activity_ prefix and preserve the number
    values_to = "activity_counts") %>%   # store the observed data in a new column names activity_counts
  mutate(minute = as.integer(minute))    # change data type

acc_1
```

Description:

*  structure of the data set:
  * the `acc_1` data set has  `r nrow(acc_1)` rows (observations) and `r ncol(acc_1)` columns (variables)
  * the variables in `acc_1` include : `r names(acc_1)`
  * the `weekday_vs_weekend` variable is a new one added to the original data set, showing whether the day is a weekday or a weekend.
  * the original data set `data_1` has `r ncol(data_1)` variables. The last 1440 columns are the activity counts of each minute in a day. 
  * We used `pivot_longer` to transform the 1440 columns to store the data in a new variable named `activity_counts` and specify the minute each data belongs to in a new variable named `minute`.



### 3. calculate total activity each day + make a table

```{r}
acc_1 %>% 
  group_by(week,day) %>% 
  summarize(total_activity = sum(activity_counts)) %>% 
  arrange(week,day) %>%       # organize data in a tidy order
  pivot_wider(
    names_from = day,
    values_from = total_activity
  ) %>% 
  knitr::kable()
  
  
```


Description of the table :
*  The daily total activities tend to fluctuate within each week, thus there is no obvious trends.
*  The daily total activity counts on Saturday in Week 4 and 5 are both 1440 which means the activity counts is 1 for each minute. The data seems abnormal. I suppose that there might be something wrong with the Accelerator that makes it unable to collect data correctly.


To better discover the trends during each week, we may make a plot.


# 4. Plot the trend of each week
```{r}
acc_1 %>% 
  group_by(week,day) %>% 
  summarize(total_activity = sum(activity_counts)) %>% 
  arrange(week,day) %>%                             # use part of the code from making the previous table
  ggplot(aes(x = day, y = total_activity, color = week, group = week)) +
  geom_point() + geom_line() + facet_grid(~week) +  # place the 5 plots in a row in the order of weeks
  labs(
  title = "Activity Trend",
  x = "Day",
  y = "Daily Total Activity") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1), 
        legend.position = "none")


```


Description of the trend plot:
* In week 1 and 2, the total activity per day increases from Monday to Friday.
* In Week 3 and 4, the fluctuations are more irregular.
* Week 5 shows an approximately increasing trend from Monday to Friday.
* The abnormal data on the Saturday of Week 4 and 5 is more obvious in the plot.




### 5. plot daily activity
```{r}
acc_1 %>%  
  group_by(day_id) %>%
  ggplot(aes(x = minute,y = activity_counts,color = day)) +
  geom_line(alpha=.5) + 
  theme(legend.position = "bottom")+
  labs(
    title = "Daily Activity",
    x = "Time in a Day",
    y = "Activity Count")+
  scale_x_continuous(
    breaks = c(0,180,360,540,720,900,1080,1260,1440),   # set the breaks of minutes in a day
    labels = c("12AM","3AM","6AM","9AM","12PM","3PM","6PM","9PM","12AM"),  # more readable x-axis labels
    limits = c(0,1440))
  
```




## Problem 3

### 1. load `ny_noaa` data set
```{r}
data("ny_noaa")
head(ny_noaa)
```


### 2. clean  data
```{r}
ny_noaa <- ny_noaa %>% 
  separate(date,into = c("year","month","day"),sep="-") %>% 
  mutate(
    year = as.numeric(year),
    month = as.integer(month),
    day = as.numeric(day),
    tmax = as.numeric(tmax)
  )

ny_noaa
  
```


### 3. snowfall
```{r}
ny_noaa %>% 
  group_by(snow) %>% 
  summarise(counts = n()) %>%  # count the occurrence of each observed snowfall data
  arrange(desc(counts))        # arrange the counts in descending order to find the most frequent ones

```

### 4. plot mean tmax
```{r}
ny_noaa %>% 
  filter(month == c(7)) %>% 
  group_by(id) %>% 
  mutate(mean_tmax = mean(tmax,na.rm = TRUE)) %>% 
  ggplot(aes(y = mean_tmax,fill = year))+
  geom_histogram()

```

```{r}


```

```{r}


```

```{r}


```

```{r}


```























